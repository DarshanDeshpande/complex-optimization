{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complex-optimization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BHtNu4-3Ut8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Setting seeds (Optional)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQhjKeu63NKn"
      },
      "source": [
        "# HYPERPARAMETERS\n",
        "NUM_SAMPLES = 1000\n",
        "lr = 0.1\n",
        "mse_loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Helper function to create dummy data\n",
        "def create_dummy_data(num_samples):\n",
        "  x = tf.expand_dims(tf.constant([complex(i/num_samples,i/num_samples) for i \n",
        "                                  in range(num_samples)], tf.complex128), -1)\n",
        "  # f(x): x -> 5x\n",
        "  y = tf.expand_dims(tf.constant([complex(5*(j/num_samples) + random.random(),\n",
        "                                          5*(j/num_samples) + random.random()) for j \n",
        "                                  in range(num_samples)], tf.complex128), -1)\n",
        "  return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDI9-nLK3NIh"
      },
      "source": [
        "# Helper function for complex optimization\n",
        "def train_complex(train_x, train_y, test_x, test_y, w):\n",
        "  for i in range(31):\n",
        "    \n",
        "    # Shuffling at the start of every epoch\n",
        "    indices = tf.range(start=0, limit=train_x.shape[0], dtype=tf.int32)\n",
        "    shuffled_indices = tf.random.shuffle(indices)\n",
        "    train_x = tf.gather(train_x, shuffled_indices)\n",
        "    train_y = tf.gather(train_y, shuffled_indices)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Get y_pred. Linear activation is used for this example\n",
        "      y_pred = tf.matmul(train_x, tf.cast(w, tf.complex128)) \n",
        "    \n",
        "      # Get real valued loss\n",
        "      mse = mse_loss(train_y, y_pred)\n",
        "    \n",
        "    if i % 10 == 0:\n",
        "      val_loss = mse_loss(test_y, tf.matmul(test_x, tf.cast(w, tf.complex128)))\n",
        "      print(f\"Training Loss at epoch {i}: {tf.abs(mse).numpy()}, Validation Loss: {tf.abs(val_loss).numpy()}\")\n",
        "\n",
        "    # Get gradients\n",
        "    dL_dw = tape.gradient(mse, w)\n",
        "\n",
        "    # Apply raw backprop\n",
        "    w.assign(w - dL_dw * lr)\n",
        "\n",
        "  print(\"Training finished\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "few-he8s3NGd"
      },
      "source": [
        "# Helper function for real optimization (split kernel approach)\n",
        "def train_real(train_x, train_y, val_x, val_y, w_real, w_imag):\n",
        "\n",
        "  # Splitting validation data into real and imaginary parts\n",
        "  val_x_real, val_x_imag = tf.math.real(val_x), tf.math.imag(val_x)\n",
        "  val_y_real, val_y_imag = tf.math.real(val_y), tf.math.imag(val_y)\n",
        "\n",
        "  for i in range(61):\n",
        "\n",
        "    # Shuffling at the start of every epoch\n",
        "    indices = tf.range(start=0, limit=train_x.shape[0], dtype=tf.int32)\n",
        "    shuffled_indices = tf.random.shuffle(indices)\n",
        "    train_x = tf.gather(train_x, shuffled_indices)\n",
        "    train_y = tf.gather(train_y, shuffled_indices)\n",
        "\n",
        "    # Splitting real and imaginary parts from shuffled data\n",
        "    x_real, x_imag = tf.math.real(train_x), tf.math.imag(train_x)\n",
        "    y_real, y_imag = tf.math.real(train_y), tf.math.imag(train_y)\n",
        "\n",
        "    with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "      # Get y_pred for real and imaginary parts separately\n",
        "      y_pred_real = tf.matmul(x_real, tf.cast(w_real, tf.float64)) \n",
        "      y_pred_imag = tf.matmul(x_imag, tf.cast(w_imag, tf.float64)) \n",
        "\n",
        "\n",
        "      # Calculate real valued losses\n",
        "      mse_real = mse_loss(y_real, y_pred_real)\n",
        "      mse_imag = mse_loss(y_imag, y_pred_imag)\n",
        "    \n",
        "    if i % 10 == 0:\n",
        "      val_pred_y_real = tf.matmul(val_x_real, tf.cast(w_real, tf.float64)) \n",
        "      val_pred_y_imag = tf.matmul(val_x_imag, tf.cast(w_imag, tf.float64)) \n",
        "      val_loss = mse_loss(val_y_real, val_pred_y_real) + mse_loss(val_y_imag, val_pred_y_imag)\n",
        "      print(f\"Training Loss at epoch {i}: {mse_real.numpy() + mse_imag.numpy()}, Validation Loss: {val_loss.numpy()}\")\n",
        "\n",
        "    \n",
        "    # Get separate gradients\n",
        "    dL_dw_r = tape1.gradient(mse_real, w_real)\n",
        "    dL_dw_i = tape2.gradient(mse_imag, w_imag)\n",
        "\n",
        "\n",
        "    # Apply raw backprop on both components\n",
        "    w_real.assign(w_real - dL_dw_r * lr)\n",
        "    w_imag.assign(w_imag - dL_dw_i * lr)\n",
        "\n",
        "\n",
        "  print(\"Training finished\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "source": [
        "# Creating dummy data\n",
        "x, y  = create_dummy_data(NUM_SAMPLES)\n",
        "# Train test split (80%-20%)\n",
        "train_x, test_x, train_y, test_y = x[:int(.8*NUM_SAMPLES), :], x[int(.8*NUM_SAMPLES):, :], y[:int(.8*NUM_SAMPLES),:], y[int(.8*NUM_SAMPLES):,:]\n",
        "\n",
        "# Initializing weights\n",
        "w = tf.Variable(tf.zeros((1,1), tf.complex128), tf.complex128)\n",
        "# Training complex optimization example\n",
        "train_complex(train_x, train_y, test_x, test_y, w)\n",
        "\n",
        "# Intializing two seprate kernels for real and imaginary domains\n",
        "w_real, w_imag = tf.Variable(tf.zeros((1,1), tf.float64)), tf.Variable(tf.zeros((1,1), tf.float64))\n",
        "# Training real optimization example\n",
        "train_real(train_x, train_y, test_x, test_y, w_real, w_imag)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}